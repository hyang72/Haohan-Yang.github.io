```
layout:     post
title:      "Machine Learning and Predictive Analytics: Convolutional Neural Networks"
date:       2022-5-17 13:00:00
author:     "Haohan"
catalog: true
header-style: text
mathjax: true
tags:

  - machine learning
  - lecture notes
  - model
```



# Importance

## Convolutional neural networks 

A **Convolutional Neural Network (ConvNet/CNN)** is a Deep Learning algorithm which can take in an input image, assign importance (learnable weights and biases) to various aspects/objects in the image and be able to differentiate one from the other. 

> [CNN](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)

![Introduction](/img/in-post/cnn_introduce.png) 

many neurons in the visual cortex have a small local **receptive field**, meaning they react only to visual stimuli located in a limited region of the visual field 

A CNN is able to **successfully capture the Spatial and Temporal dependencies** in an image through the application of relevant filters. The architecture performs a better fitting to the image dataset due to the reduction in the number of parameters involved and reusability of weights. In other words, the network can be trained to understand the sophistication of the image better.

The role of the CNN is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction

### Convolutional layers 

Neurons in the first convolutional layer are not connected to every single pixel in the input image (like they were in the dense layers before), but only **to pixels in their receptive fields**. 

In turn, each neuron in the second convolutional layer is connected only to neurons located within a small rectangle in the first layer. 

This architecture allows the network to concentrate on small low-level features in the first hidden layer, then assemble them into larger higher-level features in the next hidden layer, and so on. 

![](/img/in-post/convolutional_layerpng.png) 

**Stride**: The shift from one receptive field to the next 

**Padding**: In order for a layer to have the same height and width as the previous layer, it is common to add zeros around the inputs, as shown in the diagram. 

- **Same Padding**:  When we augment the 5x5x1 image into a 6x6x1 image and then apply the 3x3x1 kernel over it, we find that the convolved matrix turns out to be of dimensions 5x5x1
- **Valid Padding**:   if we perform the same operation without padding, we are presented with a matrix which has dimensions of the Kernel (3x3x1) itself

**Filter**: A neuronâ€™s weights can be represented as a **small image the size of the receptive field**. 

 the picture shows two sets of weights, called filters 

![](/img/in-post/filter.png) 

- a layer full of neurons using the same filter outputs a feature map, which highlights the areas in an image that activate the filter the most. 
- during training the convolutional layer will automatically learn the most useful filters for its task, and the layers above will learn to combine them into more complex patterns. 

#### **Stacking Multiple Feature Maps** : 

- Neurons in different feature maps use different parameters 
- A convolutional layer simultaneously applies multiple trainable filters to its inputs, making it capable of detecting multiple features anywhere in its inputs. 
- all neurons in a feature map share the same parameters dramatically reduces the number of parameters in the model 
- Once the CNN has learned to recognize a pattern in one location, it can recognize it in any other location. 

![](/img/in-post/stacking.png) 

```python
conv = keras.layers.Conv2D(filters=32, kernel_size=3,
                           strides=1, padding="same",
                           activation="relu")
```



### Pooling Layers

**goal**:  **decrease the computational power required to process the data**,  **extracting dominant features** which are rotational and positional invariant,

pooling neuron has **no weights**,  all it does is **aggregate the inputs** using an aggregation function such as the max or mean. 

- **Max Pooling performs a lot better than Average Pooling**.

![](/img/in-post/pooling_layer.png) 

```python
max_pool = keras.layers.MaxPool2D(pool_size=2)

# grid search
depth_pool = keras.layers.Lambda(lambda X:
                tf.nn.max_pool(X, ksize=(1, 1, 1, 3),
                               strides=(1, 1, 1, 3),
                               padding="valid"))

# global average pooling layer
global_avg_pool = keras.layers.GlobalAvgPool2D()
```

### CNN Architectures

- Typical CNN architectures stack a few convolutional layers, each one generally followed by a ReLU layer, then a pooling layer and loop
- image gets smaller but also deeper\- more feature maps

![](/img/in-post/cnn_arch.png) 

```python
###### Import data
(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()
X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]
y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]

X_mean = X_train.mean(axis=0, keepdims=True)
X_std = X_train.std(axis=0, keepdims=True) + 1e-7
X_train = (X_train - X_mean) / X_std
X_valid = (X_valid - X_mean) / X_std
X_test = (X_test - X_mean) / X_std

X_train = X_train[..., np.newaxis]
X_valid = X_valid[..., np.newaxis]
X_test = X_test[..., np.newaxis]

###### Build CNN architectures
from functools import partial

DefaultConv2D = partial(keras.layers.Conv2D,
                        kernel_size=3, activation='relu', padding="SAME")

model = keras.models.Sequential([
    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),
    keras.layers.MaxPooling2D(pool_size=2),
    DefaultConv2D(filters=128),
    DefaultConv2D(filters=128),
    keras.layers.MaxPooling2D(pool_size=2),
    DefaultConv2D(filters=256),
    DefaultConv2D(filters=256),
    keras.layers.MaxPooling2D(pool_size=2),
    keras.layers.Flatten(),
    keras.layers.Dense(units=128, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(units=64, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(units=10, activation='softmax'),
])

###### Compile Model
model.compile(loss="sparse_categorical_crossentropy", optimizer="nadam", metrics=["accuracy"])
myutils.tic()
history = model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))
myutils.toc()
score = model.evaluate(X_test, y_test)
X_new = X_test[:10] # pretend we have new images
y_pred = model.predict(X_new)
```

- It is a common practice to double the number of filters after each pooling layer: since a pooling layer divides each spatial dimension by a factor of 2 
- In the top there is a fully connected network, composed of two hidden dense layers and a dense output layer. Note that we must flatten its inputs, since a dense network expects a 1D array of features for each instance. 

### Using Pretrained Models from Keras 

